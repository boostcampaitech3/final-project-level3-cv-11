{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face tracking pipeline\n",
    "\n",
    "The following example illustrates how to use the `facenet_pytorch` python package to perform face detection and tracking on an image dataset using MTCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import numpy as np\n",
    "import mmcv, cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display\n",
    "from matplotlib import image\n",
    "from util import Mosaic, DrawRectImg\n",
    "from ml_part import Detection, Recognition\n",
    "from detection import mtcnn_detection, mtcnn_get_embeddings, mtcnn_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ProcessImage(img, bbox_thr, recog_thr, device):\n",
    "    # Object Detection\n",
    "    # bboxes = Detection(img, bbox_thr)\n",
    "    bboxes, landmarks = mtcnn_detection(img, bbox_thr, device)\n",
    "    # print(bboxes)\n",
    "    faces, unknown_embeddings = mtcnn_get_embeddings(img, bboxes, device)\n",
    "\n",
    "    # Object Recognition\n",
    "    # unknown_bboxes, face_ids = Recognition(img, bboxes, recog_thr)\n",
    "    face_ids, result_probs = mtcnn_recognition(img, unknown_embeddings, recog_thr, device)\n",
    "    # print(face_ids)\n",
    "\n",
    "    # Mosaic\n",
    "    # img = Mosaic(img, bboxes, face_ids, n=3, mode=0) \n",
    "\n",
    "    # 특정인에 bbox와 name을 보여주고 싶으면\n",
    "    processed_img = DrawRectImg(img, bboxes, landmarks, face_ids)\n",
    "\n",
    "    return processed_img\n",
    "    # return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "\n",
    "Note that, since MTCNN is a collection of neural nets and other code, the device must be passed in the following way to enable copying of objects when needed internally.\n",
    "\n",
    "See `help(MTCNN)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(keep_all=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a sample video\n",
    "\n",
    "We begin by loading a video with some faces in it. The `mmcv` PyPI package by mmlabs is used to read the video frames (it can be installed with `pip install mmcv`). Frames are then converted to PIL images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "video = mmcv.VideoReader('video.mp4')\n",
    "frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "\n",
    "display.Video('video.mp4', width=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run video through MTCNN\n",
    "\n",
    "We iterate through each frame, detect faces, and draw their bounding boxes on the video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_tracked = []\n",
    "for i, frame in enumerate(frames):\n",
    "    print('\\rTracking frame: {}'.format(i + 1), end='')\n",
    "    \n",
    "    frame_draw = ProcessImage(frame, 20, 0.8, device)\n",
    "    # Add to frame list\n",
    "    frames_tracked.append(frame_draw.resize((640, 360), Image.BILINEAR))\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = display.display(frames_tracked[0], display_id=True)\n",
    "i = 1\n",
    "try:\n",
    "    while True:\n",
    "        d.update(frames_tracked[i % len(frames_tracked)])\n",
    "        i += 1\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save tracked video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = frames_tracked[0].size\n",
    "fourcc = cv2.VideoWriter_fourcc(*'FMP4')    \n",
    "video_tracked = cv2.VideoWriter('video_tracked.mp4', fourcc, 25.0, dim)\n",
    "for frame in frames_tracked:\n",
    "    video_tracked.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
    "video_tracked.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe75d8f5c85d1d2bcf00bb7c3b774f3b57fd01eaa5f54dca43b05b67e8a1bdf2"
  },
  "kernelspec": {
   "display_name": "bc",
   "language": "python",
   "name": "bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
